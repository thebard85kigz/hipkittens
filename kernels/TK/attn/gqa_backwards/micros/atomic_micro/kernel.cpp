#include "kittens.cuh"
#include "pyutils/pyutils.cuh"
using namespace kittens;

// problem dims
constexpr int b = 1;
constexpr int h = 1;
constexpr int d = 32;          
constexpr int n = 32;      
constexpr int BLOCK_SIZE = n;

// total rows to reduce over 
constexpr int n_total = 128;

#define NUM_WARPS 1
#define NUM_THREADS (kittens::WARP_THREADS * NUM_WARPS)

using G = kittens::group<NUM_WARPS>;

struct micro_globals {
    gl<bf16, -1, -1, -1, -1> in;   
    gl<bf16, -1, -1, -1, -1> out;  
    dim3 grid()  { return dim3(n_total / BLOCK_SIZE); }  
    dim3 block() { return dim3(NUM_THREADS); }
    size_t dynamic_shared_memory() { return MAX_SHARED_MEMORY - 2048; }
};

__global__ __launch_bounds__(NUM_THREADS, 1)
void micro_tk(const micro_globals g) {
    const int tile_idx = blockIdx.x;       
    const int lane     = kittens::laneid();    

    // load one 32x32 tile
    rt_bf<n, d, row_l> tile;
    load(tile, g.in, {0, 0, tile_idx, 0});     

    __builtin_amdgcn_s_waitcnt(0);
    __builtin_amdgcn_s_barrier();
    __syncthreads();


    coord<> out_coord = {0, 0, 0, 0};
    bf16* out_ptr = (bf16*)&g.out[out_coord];
    const uint32_t out_elems = n * d;                   
    const uint32_t buffer_size = out_elems * sizeof(bf16);   
    std::uintptr_t as_int = reinterpret_cast<std::uintptr_t>(out_ptr);
    std::uint64_t  as_u64 = static_cast<std::uint64_t>(as_int);
    buffer_resource br = make_buffer_resource(as_u64, buffer_size, 0x00020000);

    // thread mappings
    const int row = lane & 31;            // 0..31
    const int start_pair = (lane >> 5) * 8;  // 0 or 8

    #pragma unroll
    for (int k = 0; k < tile.packed_per_thread; ++k) {
        // pull this laneâ€™s kth bf16_2 from the register tile
        bf16_2 val = tile.tiles[0][0].data[k];

        // which bf16_2 pair horizontally?
        const int col_pair = start_pair + k;    // 0..15
        // index of the first bf16 in that pair within the flattened [row, col] matrix
        const int elem_index = row * d + (col_pair * 2);     // two bf16 per pair
        const uint32_t byte_offset = static_cast<uint32_t>(elem_index * sizeof(bf16));

        // pack the two bf16s to a 32-bit reg
        uint32_t v_data = *reinterpret_cast<uint32_t*>(&val);

        // Atomically add 
        asm volatile(
            "buffer_atomic_pk_add_bf16 %0, %1, %2, 0 offen\n"
            "s_waitcnt vmcnt(0)\n"
            :
            : "v"(v_data), "v"(byte_offset), "s"(*(i32x4*)&br)
            : "memory"
        );
    }

    __builtin_amdgcn_s_waitcnt(0);
    __builtin_amdgcn_s_barrier();
    __syncthreads();
}

void dispatch_micro(micro_globals g) {
    unsigned long mem_size = g.dynamic_shared_memory();
    hipFuncSetAttribute((void*)micro_tk, hipFuncAttributeMaxDynamicSharedMemorySize, mem_size);
    micro_tk<<<g.grid(), g.block(), mem_size>>>(g);
    hipDeviceSynchronize();
}

PYBIND11_MODULE(tk_kernel, m) {
    m.doc() = "tk_kernel python module";
    py::bind_function<dispatch_micro>(m, "dispatch_micro", &micro_globals::in, &micro_globals::out);
}
